Ch04
================
VincentAlegrete
2024-12-24

We will do something equivalent to the t-test using Stan. Using the data
generated from the following R code, we want to decide whether the mean
parameter $\mu_1$ in group one (<tt>Y1</tt>) differs from $\mu_2$ in
group two (<tt>Y2</tt>) by computing $\text{Prob}[\mu_1 < \mu_2]$, which
is the probability of $\mu_1 < \mu_2$.

``` r
set.seed(123)
N1 <- 30
N2 <- 20
Y1 <- rnorm(n=N1, mean=0, sd=5)
Y2 <- rnorm(n=N2, mean=1, sd=4)
```

1)  Visualize the data from these two groups so that we can intuitively
    see whether the difference exists between them.

<i>Solution</i> Boxplots for $Y_1$ and $Y_2$ suggest that the
distribution centers and spreads are different.

``` r
boxplot(Y1, Y2, names=c("Y1", "Y2"), horizontal=TRUE)
```

![](Ch04_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

2)  Write a model formula with the assumption that these two groups have
    the same SD. This corresponds to the Students’ t-test.

<i>Solution</i>

With the assumption that $\text{Var}(Y_1)=\text{Var}(Y_2)$, then our
likelihoods (under flat priors for $\mu_1,\mu_2,\sigma$) are
$$Y_1|\mu_1,\sigma\sim N(\mu_1,\sigma^2)$$
$$Y_2|\mu_2,\sigma\sim N(\mu_2,\sigma^2)$$ We will build posterior
distributions for both means in the next two subproblems.

3)  Create the model file of (2) in Stan and estimate the parameters.
    Don’t use <tt>generated quantities</tt> block here yet, because in
    the next (4) we will be practicing how to make use of draws from R
    or Python.

``` stan
data {
  int N1;
  int N2;
  vector[N1] Y1;
  vector[N2] Y2;
}

parameters {
  real mu1;
  real mu2;
  real<lower=0> sigma;
}

model {
  Y1 ~ normal(mu1, sigma);
  Y2 ~ normal(mu2, sigma);
}
```

4)  Compute Prob\[μ1 \< μ2\] from the obtained draws using R or Python
    (hint: we can count how many times the event μ1 \< μ2 occurs in the
    entire draws, and divide this quantity by the total number of
    draws).

<i>Solution</i> We run the model in STAN, generate our posterior draws,
and display the model summary.

``` r
library(cmdstanr)
data <- list(N1=N1, N2=N2, Y1=Y1, Y2=Y2)
# model3 <- cmdstan_model(stan_file='model3.stan')
fit <- model3$sample(data=data, seed=200)
```

    ## Running MCMC with 4 sequential chains...
    ## 
    ## Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) 
    ## Chain 1 Iteration:  100 / 2000 [  5%]  (Warmup) 
    ## Chain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) 
    ## Chain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) 
    ## Chain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) 
    ## Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) 
    ## Chain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) 
    ## Chain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) 
    ## Chain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) 
    ## Chain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) 
    ## Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
    ## Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
    ## Chain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) 
    ## Chain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) 
    ## Chain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) 
    ## Chain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) 
    ## Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) 
    ## Chain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) 
    ## Chain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) 
    ## Chain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) 
    ## Chain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) 
    ## Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) 
    ## Chain 1 finished in 0.0 seconds.
    ## Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) 
    ## Chain 2 Iteration:  100 / 2000 [  5%]  (Warmup) 
    ## Chain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) 
    ## Chain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) 
    ## Chain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) 
    ## Chain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) 
    ## Chain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) 
    ## Chain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) 
    ## Chain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) 
    ## Chain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) 
    ## Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
    ## Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
    ## Chain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) 
    ## Chain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) 
    ## Chain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) 
    ## Chain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) 
    ## Chain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) 
    ## Chain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) 
    ## Chain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) 
    ## Chain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) 
    ## Chain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) 
    ## Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) 
    ## Chain 2 finished in 0.0 seconds.
    ## Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) 
    ## Chain 3 Iteration:  100 / 2000 [  5%]  (Warmup) 
    ## Chain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) 
    ## Chain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) 
    ## Chain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) 
    ## Chain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) 
    ## Chain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) 
    ## Chain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) 
    ## Chain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) 
    ## Chain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) 
    ## Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
    ## Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
    ## Chain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) 
    ## Chain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) 
    ## Chain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) 
    ## Chain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) 
    ## Chain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) 
    ## Chain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) 
    ## Chain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) 
    ## Chain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) 
    ## Chain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) 
    ## Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) 
    ## Chain 3 finished in 0.0 seconds.
    ## Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) 
    ## Chain 4 Iteration:  100 / 2000 [  5%]  (Warmup) 
    ## Chain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) 
    ## Chain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) 
    ## Chain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) 
    ## Chain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) 
    ## Chain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) 
    ## Chain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) 
    ## Chain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) 
    ## Chain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) 
    ## Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
    ## Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
    ## Chain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) 
    ## Chain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) 
    ## Chain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) 
    ## Chain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) 
    ## Chain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) 
    ## Chain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) 
    ## Chain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) 
    ## Chain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) 
    ## Chain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) 
    ## Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) 
    ## Chain 4 finished in 0.0 seconds.
    ## 
    ## All 4 chains finished successfully.
    ## Mean chain execution time: 0.0 seconds.
    ## Total execution time: 0.7 seconds.

``` r
fit$cmdstan_summary()
```

    ## Inference for Stan model: model_2a691b2dca5b164356fe35b71cf22e71_model
    ## 4 chains: each with iter=1000; warmup=1000; thin=1; 1000 iterations saved.
    ## 
    ## Warmup took (0.014, 0.014, 0.013, 0.015) seconds, 0.056 seconds total
    ## Sampling took (0.020, 0.021, 0.022, 0.024) seconds, 0.087 seconds total
    ## 
    ##                  Mean     MCSE  StdDev    MAD        5%    50%   95%  ESS_bulk  ESS_tail  R_hat
    ## 
    ## lp__              -98  3.0e-02     1.3    1.0  -1.0e+02    -97   -96      1927      2458    1.0
    ## accept_stat__    0.91  8.7e-03    0.11  0.071      0.69   0.95   1.0      2760      3686    1.0
    ## stepsize__       0.79      nan   0.095  0.062      0.64   0.83  0.88       nan       nan    nan
    ## treedepth__       2.3      nan    0.55   0.00       1.0    2.0   3.0        40        29    1.1
    ## n_leapfrog__      4.7      nan     2.0   0.00       3.0    3.0   7.0        48        40    1.1
    ## divergent__      0.00      nan    0.00   0.00      0.00   0.00  0.00       nan       nan    nan
    ## energy__           99  4.6e-02     1.8    1.6        97     99   103      1558      2181    1.0
    ## 
    ## mu1             -0.24  1.3e-02    0.82   0.79  -1.6e+00  -0.25   1.1      4007      3244    1.0
    ## mu2               1.6  1.6e-02     1.0    1.0  -9.6e-02    1.6   3.3      4026      2590    1.0
    ## sigma             4.5  8.4e-03    0.49   0.48   3.8e+00    4.5   5.4      3528      2752    1.0
    ## 
    ## Samples were drawn using hmc with nuts.
    ## For each parameter, ESS_bulk and ESS_tail measure the effective sample size for the entire sample (bulk) and for the .05 and .95 tails (tail), 
    ## and R_hat measures the potential scale reduction on split chains. At convergence R_hat will be very close to 1.00.

Now, we store the posterior draws into a data frame and compute
$\text{Prob}[\mu_1 < \mu_2]$ as relative frequency:

``` r
draws <- data.frame(fit$draws())
prob = (sum(draws$X1.mu1 < draws$X1.mu2) +
        sum(draws$X2.mu1 < draws$X2.mu2) +
        sum(draws$X3.mu1 < draws$X3.mu2) +
        sum(draws$X4.mu1 < draws$X4.mu2) ) / 4000
prob
```

    ## [1] 0.92575

So the posterior probability that $\mu_1 < \mu_2$ is approximately
$92.35\%$.

5)  Write a model formula with the assumption that the two SDs are
    different. This is equivalent to the Welch’s t-test. Similarly,
    compute Prob\[μ1 \< μ2\].
